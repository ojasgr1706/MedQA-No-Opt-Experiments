{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db0096bf-dc7e-4e01-8513-7aca68745114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from transformers import AutoTokenizer, GPT2Model\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28d7d25-024a-42fe-bfd8-36b72fd01f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.train_data = [\"../extracted_text/kumar_and_clark/kumar_and_clark_top_3.txt\",\"../extracted_text/Harrison/Harrison_top_3.txt\"]\n",
    "        self.test_data = \"\"\n",
    "        self.model_name = \"gpt2-xl\"\n",
    "        self.output_dir = f\"../model/qa_models/{self.model_name}-medicine/\"\n",
    "    \n",
    "def str_or_list(val):\n",
    "    if re.search(r\"^\\[\",val):\n",
    "        sep_list = val.strip(\"[]\").split(',')\n",
    "        return sep_list\n",
    "    return [val]\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--train_data\", help=\"Add input data files (single file name or list fo files in the format : [a,b,c,...]. The files in the list will be concatenated before being used as training data)\", required=True, type=str_or_list)\n",
    "# parser.add_argument(\"--test_data\", help=\"Add testing data files (single file name or list fo files in the format : [a,b,c,...]. The files in the list will be concatenated before being used as training data)\", required=False, type=str_or_list)\n",
    "# parser.add_argument(\"--model_name\", help=\"Model and tokenizer name\", required=True, type=str)\n",
    "# parser.add_argument(\"--output_dir\", help=\"Directory to save the trained models and checkpoints\", required=False, type=str, default=\"./\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = Args()\n",
    "# print(\"example :\")\n",
    "# print(dataset['train'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5915528b-8792-40b0-b2d1-4417e5baa6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../extracted_text/short_cases_medicine/short_cases_medicine_annotated.json\", 'r') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbedf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'med_hist': \"INSTRUCTION Examine this patient's chest. Examine this patient's chest from the back. Examine this patient's chest from the front. SALIENT FEATURES History · Fever. · Pleuritic pain (made worse on coughing or deep breathing). · Cough (pneumonia, TB). · Haemoptysis (associated parenchymal involvement in bronchogenic carcinoma or TB). · Shortness of breath (large effusions, cardiac failure). · Exposure to asbestos (mesothelioma). · Nephrotic syndrome. Examination · Decreased movement on the affected side. · Tracheal deviation to the opposite side. * Stony dull note on the affected side. · Decreased vocal resonance and diminished breath sounds on the affected side. Proceed as follows: · Comment on aspiration marks. · Percuss for the upper level of effusion in the axilla. · Listen for bronchial breath sounds. · Listen for aegophony at the upper level of the effusion. · It is important to elicit any evidence of an underlying cause, such as clubbing, tar staining, lymph nodes, radiation burns and mastectomy, raised JVP, rheumatoid hands or butterfly rash. Remember. 500 mi of pleural fluid should be present for clinical detection and there are 5 major types of pleural effusion: exudate, transudate, empyema, haemor-rhagic pleural effusion or haemothorax, and chylous effusion. DIAGNOSIS This patient has a pleural effusion (lesion), probably due to bronchogenic carci-noma, and is short of breath at rest (functional status).  \",\n",
       "  'ques': 'How would you investigate this patient?\\n',\n",
       "  'ans': 'Chest radiography (CXR)Standard posteroanterior and lateral chest radiographs detect pleural fluid in excess of 175 ml. Obliteration of costophrenic angle tohemithorax suggests fluid. Sub-pulmonic effusion can simulate an elevated diaphragm.Pleural tap·       Pleural fluid for determination of the levels of protein, albumin, LDH, glucose, cholesterol and cytology. A simultaneous bloodsample should be obtained for estimation of glucose, protein, albumin and LDH.·       When empyema is suspected or seen, pleural fluid pH should be obtained.·       When tuberculosis is suspected, pleural fluid adenosine deaminase or lysozyme levels should be determined andZiehl-Neelsen staining and pleural fluid myco-bacterial cultures should be done.·       Pleural fluid amylase levels should be estimated when malignancy, pancreatitis or oesophageal rupture is suspected.·       In autoimmune disorders, pleural fluid rheumatoid factor or antinuclear anti-bodies should be tested.P!eural biopsyThe biopsy specimen is sent for histopathological examination and mycobacterial culture.\\n'},\n",
       " {'med_hist': \"INSTRUCTION Examine this patient's chest. Examine this patient's chest from the back. Examine this patient's chest from the front. SALIENT FEATURES History · Fever. · Pleuritic pain (made worse on coughing or deep breathing). · Cough (pneumonia, TB). · Haemoptysis (associated parenchymal involvement in bronchogenic carcinoma or TB). · Shortness of breath (large effusions, cardiac failure). · Exposure to asbestos (mesothelioma). · Nephrotic syndrome. Examination · Decreased movement on the affected side. · Tracheal deviation to the opposite side. * Stony dull note on the affected side. · Decreased vocal resonance and diminished breath sounds on the affected side. Proceed as follows: · Comment on aspiration marks. · Percuss for the upper level of effusion in the axilla. · Listen for bronchial breath sounds. · Listen for aegophony at the upper level of the effusion. · It is important to elicit any evidence of an underlying cause, such as clubbing, tar staining, lymph nodes, radiation burns and mastectomy, raised JVP, rheumatoid hands or butterfly rash. Remember. 500 mi of pleural fluid should be present for clinical detection and there are 5 major types of pleural effusion: exudate, transudate, empyema, haemor-rhagic pleural effusion or haemothorax, and chylous effusion. DIAGNOSIS This patient has a pleural effusion (lesion), probably due to bronchogenic carci-noma, and is short of breath at rest (functional status).  \",\n",
       "  'ques': 'What are the causes of dullness at a lung base?\\n',\n",
       "  'ans': '· Pleural effusion.· Pleural thickening.· Consolidation and collapse of the lung.· Raised hemidiaphragm.\\n'},\n",
       " {'med_hist': \"INSTRUCTION Examine this patient's chest. Examine this patient's chest from the back. Examine this patient's chest from the front. SALIENT FEATURES History · Fever. · Pleuritic pain (made worse on coughing or deep breathing). · Cough (pneumonia, TB). · Haemoptysis (associated parenchymal involvement in bronchogenic carcinoma or TB). · Shortness of breath (large effusions, cardiac failure). · Exposure to asbestos (mesothelioma). · Nephrotic syndrome. Examination · Decreased movement on the affected side. · Tracheal deviation to the opposite side. * Stony dull note on the affected side. · Decreased vocal resonance and diminished breath sounds on the affected side. Proceed as follows: · Comment on aspiration marks. · Percuss for the upper level of effusion in the axilla. · Listen for bronchial breath sounds. · Listen for aegophony at the upper level of the effusion. · It is important to elicit any evidence of an underlying cause, such as clubbing, tar staining, lymph nodes, radiation burns and mastectomy, raised JVP, rheumatoid hands or butterfly rash. Remember. 500 mi of pleural fluid should be present for clinical detection and there are 5 major types of pleural effusion: exudate, transudate, empyema, haemor-rhagic pleural effusion or haemothorax, and chylous effusion. DIAGNOSIS This patient has a pleural effusion (lesion), probably due to bronchogenic carci-noma, and is short of breath at rest (functional status).  \",\n",
       "  'ques': 'How would you differentiate between the above?\\n',\n",
       "  'ans': '·       Pleural effusion: stony dull note; trachea may be deviated to the opposite side in large effusions.·       Pleural thickening: trachea not deviated; breath sounds will be heard.·       Consolidation: vocal resonance increased; bronchial breath sounds and associated crackles.·       Collapse: trachea deviated to the affected side; absent breath sounds.\\n'},\n",
       " {'med_hist': \"INSTRUCTION Examine this patient's chest. Examine this patient's chest from the back. Examine this patient's chest from the front. SALIENT FEATURES History · Fever. · Pleuritic pain (made worse on coughing or deep breathing). · Cough (pneumonia, TB). · Haemoptysis (associated parenchymal involvement in bronchogenic carcinoma or TB). · Shortness of breath (large effusions, cardiac failure). · Exposure to asbestos (mesothelioma). · Nephrotic syndrome. Examination · Decreased movement on the affected side. · Tracheal deviation to the opposite side. * Stony dull note on the affected side. · Decreased vocal resonance and diminished breath sounds on the affected side. Proceed as follows: · Comment on aspiration marks. · Percuss for the upper level of effusion in the axilla. · Listen for bronchial breath sounds. · Listen for aegophony at the upper level of the effusion. · It is important to elicit any evidence of an underlying cause, such as clubbing, tar staining, lymph nodes, radiation burns and mastectomy, raised JVP, rheumatoid hands or butterfly rash. Remember. 500 mi of pleural fluid should be present for clinical detection and there are 5 major types of pleural effusion: exudate, transudate, empyema, haemor-rhagic pleural effusion or haemothorax, and chylous effusion. DIAGNOSIS This patient has a pleural effusion (lesion), probably due to bronchogenic carci-noma, and is short of breath at rest (functional status).  \",\n",
       "  'ques': 'How would you differentiate between an exudate and a transudate?\\n',\n",
       "  'ans': \"·       The protein content of an exudate is more than 3 g/l. However, if this criterion alone is applied, about 10% of the exudates and15% of the transudates will be wrongly classified. A more accurate diagnosis is made when Light's criteria (Ann Intern Med1972; 77: 507-13) for an exudate are applied: (1) the ratio of the pleural fluid to serum protein is greater than 0.5; (2) the ratio ofpleural fluid to serum lactic dehydrogenase (LDH) is greater than 0.6; (3) pleural fluid LDH is greater than two thirds the uppernormal limit for blood LDH levels. Roth et al (1990) found that, althomzh Light's criteria had a sensitivity of 100%, they had alow specificity of 72% (Chest 1990; 98: 546-9). This was due to the fact that many patients with effusion due to chronic cardiacfailure have protein values inthe exudate range, particularly when on chronic diuretic therapy. They found that the serum-effusion albumin gradient (i.e. serumalbumin minus pleural fluid albumin) was 95% sensitive but a more specific (100%) marker of exudative effusion. A gradient of lessthan 1.2 g/dl indicates an exudative effusion whereas a gradient greater than 1.2 g/dl indicates a transudative effusion.·       The pleural fluid cholesterol level is below 60 mg/dl in transudates. All malignant effusions have a pleural cholesterol levelgreater than this value, and therefore this test is useful to separate these two categories of effusion (Chest 1987; 92: 296-302;Chest1991; 99: 1097-102).\\n\"},\n",
       " {'med_hist': \"INSTRUCTION Examine this patient's chest. Examine this patient's chest from the back. Examine this patient's chest from the front. SALIENT FEATURES History · Fever. · Pleuritic pain (made worse on coughing or deep breathing). · Cough (pneumonia, TB). · Haemoptysis (associated parenchymal involvement in bronchogenic carcinoma or TB). · Shortness of breath (large effusions, cardiac failure). · Exposure to asbestos (mesothelioma). · Nephrotic syndrome. Examination · Decreased movement on the affected side. · Tracheal deviation to the opposite side. * Stony dull note on the affected side. · Decreased vocal resonance and diminished breath sounds on the affected side. Proceed as follows: · Comment on aspiration marks. · Percuss for the upper level of effusion in the axilla. · Listen for bronchial breath sounds. · Listen for aegophony at the upper level of the effusion. · It is important to elicit any evidence of an underlying cause, such as clubbing, tar staining, lymph nodes, radiation burns and mastectomy, raised JVP, rheumatoid hands or butterfly rash. Remember. 500 mi of pleural fluid should be present for clinical detection and there are 5 major types of pleural effusion: exudate, transudate, empyema, haemor-rhagic pleural effusion or haemothorax, and chylous effusion. DIAGNOSIS This patient has a pleural effusion (lesion), probably due to bronchogenic carci-noma, and is short of breath at rest (functional status).  \",\n",
       "  'ques': 'Mention a few causes for an exudate and a transudate.\\n',\n",
       "  'ans': 'Causes for an exudate: · Bronchogenic carcinoma (presence of effusion is an ominous sign).· Secondaries in the pleura (lung, breast, ovary and pancreas).· Pneumonia.· Pulmonary infarction.· Tuberculosis.· Rheumatoid arthritis.· SLE.· Lymphoma (in young individuals).· Mesothelioma. Causes of a transudate: · Nephrotic syndrome.· Cardiac failure.· Liver cell failure.· Hypothyroidism.\\n'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = json_data['respiratory']\n",
    "resp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6aa93e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"text\" : f\"{elem['med_hist']}\\n{elem['ques']}\", \"labels\" : elem['ans']} for elem in resp]\n",
    "# labels = [{\"text\" : elem['ans']} for elem in resp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fd02f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train = Dataset.from_list(train)\n",
    "test = Dataset.from_list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "849ce1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 129\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 33\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DatasetDict({\"train\" : train, \"test\" : test})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d426c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9b07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a2500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1d77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d715c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b812f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9768ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24176e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "21ebf0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "stride = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0c09b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    text_ids = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        # max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "        # padding=True,\n",
    "        # stride=stride\n",
    "    )\n",
    "\n",
    "    label_ids = tokenizer(\n",
    "        element[\"label\"],\n",
    "        truncation=True,\n",
    "        # max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "        # padding=True,\n",
    "        # stride=stride\n",
    "    )\n",
    "\n",
    "    text_batch = []\n",
    "    label_batch = []\n",
    "    for text_id, label_id in zip(text_ids[\"input_ids\"], label_ids[\"input_ids\"]):\n",
    "        # if length == context_length:\n",
    "        text_batch.append(text_id)\n",
    "        label_batch.append(label_id)\n",
    "    return {\"text_ids\": text_batch, \"label_ids\" : label_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1291861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd71d88223848d6a7812516cc96ab05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10620ae1784c4f388ca2ea56ccb2f81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b99c434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets['train']\n",
    "test_dataset = tokenized_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e4a52dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_ids', 'label_ids'],\n",
       "    num_rows: 129\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b714b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081ef52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729c5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164aa99-4b06-4a38-b214-50b7144f6ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512af34-eab4-4e8c-9352-4e847a61c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20da4d-44c7-4cbe-8d1e-ac73f9f0f34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaf272-497d-41b8-8cf4-fc1927a4f737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04336e-393a-4a96-9c28-324657c4a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(args.test_data):\n",
    "#     dataset = load_dataset('text',data_files={'train': args.train_data, 'test': args.test_data})\n",
    "# else:\n",
    "#     dataset = load_dataset('text',data_files={'train': args.train_data})\n",
    "\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ced1c309-b60d-4b35-9f6d-a97c61a5211d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec007615da7c414f85b8529c66e3c8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0342dd2720bf4ca2a23cec30b94345cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text_ids', 'label_ids'],\n",
      "        num_rows: 129\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text_ids', 'label_ids'],\n",
      "        num_rows: 33\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# context_length = 512\n",
    "# stride = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize(element):\n",
    "    text_ids = tokenizer(\n",
    "        element[\"text\"],\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    label_ids = tokenizer(\n",
    "        element[\"label\"],\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "    text_batch = []\n",
    "    label_batch = []\n",
    "    for text_id, label_id in zip(text_ids[\"input_ids\"], label_ids[\"input_ids\"]):\n",
    "        text_batch.append(text_id)\n",
    "        label_batch.append(label_id)\n",
    "\n",
    "    return {\"text_ids\": text_batch, \"label_ids\" : label_batch}\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "print(tokenized_datasets)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9ad800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets['train'][0]['text_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a399d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7c313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c23f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57158f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b027ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causallm_loss(logits, labels):\n",
    "    \n",
    "    # Shift so that tokens < n predict n\n",
    "    # shift_labels = inputs[..., 1:].contiguous()\n",
    "    # shift_logits = logits[..., :-1, :].contiguous()\n",
    "\n",
    "\n",
    "\n",
    "    preds = logits.view(-1, logits.size(-1))\n",
    "    targets = labels.view(-1)\n",
    "    # targets = targets.clone()\n",
    "    # targets[:stride-1] = -100\n",
    "\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduction='mean')\n",
    "    loss = loss_fct(preds, targets)\n",
    "    # print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b3a16-155c-4480-9f5f-12261450b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accelerate training loop\n",
    "\n",
    "def training_loop(args, dataset, mixed_precision=\"fp16\"):\n",
    "    \n",
    "    # model_name = \"bloom-1b1\"\n",
    "    model_name = args.model_name\n",
    "    \n",
    "    accelerator = Accelerator(mixed_precision = mixed_precision)\n",
    "    accelerator.print(\"accelerator initialised\")\n",
    "    \n",
    "    set_seed(42)\n",
    "    accelerator.print(\"seed set\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(f\"{model_name}\")\n",
    "    accelerator.print(\"model loaded\")\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset['train'], shuffle=False, batch_size=1)\n",
    "    \n",
    "    # HYPERPARAMETERS\n",
    "    \n",
    "    num_epochs = 30\n",
    "    warm_up_steps = num_epochs//5 * len(train_dataloader)\n",
    "    training_steps = 4*num_epochs//5 * len(train_dataloader)\n",
    "    lr = 1e-5\n",
    "    checkpoint = True\n",
    "    load_checkpoint = False\n",
    "    evaluate = False\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    train_dataloader, model, optimizer = accelerator.prepare(\n",
    "        train_dataloader, model, optimizer\n",
    "    )\n",
    "    \n",
    "    if(args.test_data):\n",
    "        test_dataloader = DataLoader(dataset['test'], batch_size=1)\n",
    "        test_dataloader = accelerator.prepare(test_dataloader)\n",
    "        \n",
    "    accelerator.print(\"dataloaders initialised\")\n",
    "\n",
    "    accelerator.print(\"scheduler initialised\")\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer, num_warmup_steps=warm_up_steps, num_training_steps=training_steps\n",
    "    )\n",
    "    \n",
    "    # Training conditions    \n",
    "    \n",
    "    if load_checkpoint:\n",
    "        model.load_state_dict(torch.load(f'{args.output_dir}/{model_name}_medicine_epoch{epoch}.pth'))\n",
    "\n",
    "    progress_bar = tqdm(range(training_steps))\n",
    "    epoch_losses = []\n",
    "    best = 1\n",
    "    \n",
    "    loss_fct = CrossEntropyLoss(reduction='mean')\n",
    "    model.train()\n",
    "    accelerator.print(\"training started\")\n",
    "    for epoch in range(num_epochs):\n",
    "        step_losses = []\n",
    "        for step,batch in enumerate(train_dataloader, start = 1):\n",
    "            # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits = model(batch['input_ids']).logits\n",
    "            labels = batch['labels']\n",
    "            # loss = causallm_loss(logits,batch)\n",
    "\n",
    "            preds = logits.view(-1, logits.size(-1))\n",
    "            targets = labels.view(-1)\n",
    "            # targets = targets.clone()\n",
    "            # targets[:stride-1] = -100\n",
    "\n",
    "            loss = loss_fct(preds, targets)\n",
    "            # loss.backward()\n",
    "            accelerator.backward(loss)\n",
    "            step_losses.append([step,loss.item()])\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        epoch_loss = sum(step_losses)/len(step_losses)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        ppl = np.exp(epoch_loss)\n",
    "        with open(f\"{args.output_dir}resp_train_logs.txt\",\"a\") as f:\n",
    "            f.write(f\"loss : {epoch_loss:.3f} , perplexity : + {ppl:.3f} \\n\")\n",
    "\n",
    "        if epoch_loss < epoch_losses[best-1]:\n",
    "            best = len(epoch_losses)\n",
    "        \n",
    "        if(checkpoint):\n",
    "            torch.save(model.state_dict(),f'{args.output_dir}/{model_name}_medicine_epoch{epoch}.pth')\n",
    "                \n",
    "    accelerator.print(\"training ended\")\n",
    "    accelerator.print(epoch_losses)\n",
    "    with open(\"../model/trained_models/logs.txt\",\"w\")as f:\n",
    "        f.write(f\"best = {best}\\n\" + str(epoch_losses))\n",
    "    # torch.save(model.state_dict(),f'../model/trained_models/{model_name}_harrison_respiratory.pth')\n",
    "    accelerator.print(\"best saved\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99939e74-7c7c-4a2d-a0c9-df45046b7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(args, tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e9a50f34-38a4-45db-8a06-b5c816a04938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets['train'], shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f9590eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 129\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 33\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4059a37a-d8fb-4b7f-9961-6079522b2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_dataloader)\n",
    "sample = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "44f16a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3268, 46126,  2849,  1475,  9862,   428,  5827,   338,  7721,    13,\n",
       "         42475, 28495, 18630, 47471,  7443, 14128, 41951,   290,  1755, 39387,\n",
       "            13, 14128,  4434,    64,   786,    11, 18787,    11,   281,   382,\n",
       "         36072,    13, 14128, 14331,  2994,    13, 14128,   327,   619,   351,\n",
       "           599,   315,   388,    13, 50105,  2312,     6,  8071,  2334,  4327,\n",
       "           284,   423,  5895,   286,  2219,  7721, 10040,   543,   389,   407,\n",
       "          2005,   290, 16577,    13,  1318,   389,  1811,   285,  2812,   329,\n",
       "           428,    11,   884,   355,  3339,  1523,  6546,  3101,    11, 41899,\n",
       "           330, 38385,   290, 29631,   261, 42505,    11,  3917,  7375,  2885,\n",
       "            11,  3917,  7721, 10280,    11,   458,  2381,   496,   393,   872,\n",
       "           918,   291, 16384, 19813,    13,   383,  1708,  2148,   617,  6096,\n",
       "            25, 35550,   352,   383,  4540,   373,  1965,   284, 10716,   262,\n",
       "          7721,   422,   262,  2166,    11,   355,   257,  1255,   286,   543,\n",
       "           262,  1468, 41899,   330, 38385, 10153,   373,   407,  1775,    13,\n",
       "           383,  5827,   373,   483,    68,  7357,    13,   383,   491,  4891,\n",
       "            64,   373,  1614, 12931,   284,   262,   826,    13,  2448, 36262,\n",
       "          3465,   373,   336,  1647, 19222,   422,   262,   826,  1218,   987,\n",
       "            12, 15805,   282,  2272, 44890,    13,  5792,    68,  2736,   373,\n",
       "          1944,   319,   262,  1364,  1735,    13,   770,  5827,   550,   257,\n",
       "           826, 29631,   261, 42505,   351,  7375,  2885,   287,   262,  1364,\n",
       "         12317,    13,   383,  4540,   338, 13669,   286,   826,    12, 22339,\n",
       "          3339,  1523,   914,  4241,   351, 10238,  9807,   290,  1364,    12,\n",
       "         22339,  7375,  2885,   373,  6292,    13, 35550,   362,   383,   491,\n",
       "          4891,    64,   373,  4318,    13,   317,   872,   918,   291, 16384,\n",
       "         19813, 10153,   373,  1775,    13,  2448, 36262,  3465,   373, 19222,\n",
       "           287,   262,  1364,  1167,   430,    12,   897, 15856,  3814,   290,\n",
       "           612,   547,  3917,  8469,   829,    13,   383,  2566,   363,    12,\n",
       "         31707,   286,  3339,  1523,  6546,  3101,   351,  3917,  7721, 10280,\n",
       "           373,  6292,    26,   326,   286,  3339,  1523,   914,  4241,   373,\n",
       "           407,    13,   220,   198, 17353,   345, 28091,   257,  5827,   351,\n",
       "          8308, 14641,    11,   599,   315,   388,    12, 24561,    11, 45105,\n",
       "         23799,    30,   198]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['text_ids'] + sample['label_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacda2b-ee9a-4fdc-ad7a-d0937f1d2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14ac3c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.tensor([[1,2,3]]), torch.tensor([[4,5,6]])), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d32ce6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3]]).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b019ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c87b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd604f2-c495-48b9-bcd6-c0d544133d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b3329-49a7-42a6-9d9b-29e10a2eb92b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
